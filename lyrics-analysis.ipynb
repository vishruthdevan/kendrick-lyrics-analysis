{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17637df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/kendrick_lamar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f78eea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Track Title Release Title Release Subtitle  Track #  \\\n",
      "0       Fuck Your Ethnicity    Section.80              NaN        1   \n",
      "1                   Hol' Up    Section.80              NaN        2   \n",
      "2                  A.D.H.D.    Section.80              NaN        3   \n",
      "3     No Make-Up (Her Vice)    Section.80              NaN        4   \n",
      "4  Tammy's Song (Her Evils)    Section.80              NaN        5   \n",
      "\n",
      "  Track Length (mm:ss)     Featuring Release Type  Release Type #  \\\n",
      "0                 3:44  Colin Munroe       Studio             1.0   \n",
      "1                 2:53           NaN       Studio             1.0   \n",
      "2                 3:35           NaN       Studio             1.0   \n",
      "3                 3:55           NaN       Studio             1.0   \n",
      "4                 2:41           NaN       Studio             1.0   \n",
      "\n",
      "  Release Date  # of Tracks  ... Jaguar Maserati McLaren Mercedes-Benz  \\\n",
      "0     2 Jul 11         16.0  ...    NaN      NaN     NaN           1.0   \n",
      "1     2 Jul 11         16.0  ...    1.0      NaN     NaN           NaN   \n",
      "2     2 Jul 11         16.0  ...    NaN      NaN     NaN           NaN   \n",
      "3     2 Jul 11         16.0  ...    NaN      NaN     NaN           NaN   \n",
      "4     2 Jul 11         16.0  ...    NaN      NaN     NaN           1.0   \n",
      "\n",
      "  Porsche Range Rover  RAV4 Silverado Toyota Van  \n",
      "0     NaN         NaN   NaN       NaN    NaN NaN  \n",
      "1     NaN         NaN   1.0       NaN    NaN NaN  \n",
      "2     NaN         NaN   NaN       NaN    NaN NaN  \n",
      "3     NaN         NaN   NaN       NaN    NaN NaN  \n",
      "4     NaN         NaN   NaN       NaN    NaN NaN  \n",
      "\n",
      "[5 rows x 238 columns]\n",
      "0    Gather 'round\\n I'm glad everybody came out to...\n",
      "1    I wrote this record while thirty thousand feet...\n",
      "2    Uh-uh, fuck that\\n Eight doobies to the face, ...\n",
      "3    I love the way you put it on your eyes\\n The r...\n",
      "4    Don't judge me\\n I know this girl, she a real ...\n",
      "Name: Lyrics, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data['Lyrics'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa79bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gather 'round\n",
      " I'm glad everybody came out tonight\n",
      " As we stand on our neighborhood corner\n",
      " Know that this fire that's burning represents the passion you have\n",
      " Listen\n",
      " Keisha, Tammy, come up front\n",
      " I recognize all of you\n",
      " Every creed and color\n",
      " With that being said\n",
      " Fuck your ethnicity\n",
      " You understand that?\n",
      " We gon' talk about a lot of shit that concerns you, all of you\n",
      " Now everybody, throw your hands up high\n",
      " If you don't give a fuck, throw your hands up high\n",
      " Throw your hands up high\n",
      " Now, I don't give a fuck if you\n",
      " Black, white, Asian, Hispanic, goddammit\n",
      " That don't mean shit to me\n",
      " Fuck your ethnicity, nigga\n",
      " Fire burning inside my eyes, this the music that saved my life\n",
      " Y'all be calling it hip-hop, I be calling it hypnotize\n",
      " Yeah, hypnotize, trapped my body, but freed my mind\n",
      " What the fuck are you fighting for? Ain't nobody gon' win that war\n",
      " My details be retail, man, I got so much in store\n",
      " Racism is still alive, yellow tape and colored lines\n",
      " Fuck that, nigga, look at that line, it's so diverse\n",
      " They gettin' off work and they wanna see Kendrick\n",
      " Everybody can't drive Benzes, and I been there, so I make it my business\n",
      " To give 'em my full attention, ten-hut, man, I gotta get my wind up\n",
      " Man, I gotta get down with God 'cause I got my sins up, ooh\n",
      " Matter fact, don't mistake me for no fuckin' rapper\n",
      " They sit backstage and hide behind them fuckin' cameras\n",
      " I mosh pit, had a microphone and I tossed it\n",
      " Had a brain, then I lost it\n",
      " I'm out of my mind, so don't you mind how much the cost is\n",
      " Penny for my thoughts, everybody, please hold up your wallets\n",
      " Yeah, man, I'm the mailman, can't you tell, man?\n",
      " Gone postal, never freeze up when I approach you\n",
      " That's starstruck and roast you, oh my\n",
      " HiiiPoWeR\n",
      " Reporting live from Planet Terminator X\n",
      " I saw Martin Luther King with an AK-47\n",
      " Now, I don't give a fuck if you\n",
      " Black, white, Asian, Hispanic, goddammit\n",
      " That don't mean shit to me\n",
      " Fuck your ethnicity, nigga\n",
      " I'm tired of y'all, 'cause everybody lied to y'all\n",
      " And you believe it? Recognize them false achievements\n",
      " It's treason and I'm Tylenol, I knock out when you knock it off\n",
      " Knock on the doors of opportunity, I'm too involved\n",
      " I'm no activist, I'm no Einstein\n",
      " Before calculus, I was kicking that math\n",
      " Dropping that science like an alchemist and I be kicking that ass\n",
      " Lyrically, I'm UFC\n",
      " If a UFO had came for me, I'ma come back with the head of an alien\n",
      " Don't alienate my dreams\n",
      " Get it right, get a life, I got two\n",
      " That's a metaphor for the big shit I do\n",
      " Boy, TMI, TSA, man, I'm fly\n",
      " Put wings on my back\n",
      " That a plane or an angel? Both\n",
      " Like a pilot with a halo, woah\n",
      " Gross\n",
      " I mean, I've seen so many things come through them, him, her, you, mmm, mmm, mmm, mmm\n",
      " I'm just a messenger\n",
      " Yeah, I know life's a bitch, get the best of her\n",
      " Put them threes up, they notice that we up\n",
      " HiiiPoWeR and the power in the people and if they don't believe us\n",
      " They'll die\n",
      " Wizard\n",
      " Now, I don't give a fuck if you\n",
      " Black, white, Asian, Hispanic, goddammit\n",
      " That don't mean shit to me\n",
      " Fuck your ethnicity, nigga\n"
     ]
    }
   ],
   "source": [
    "print(data['Lyrics'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a981200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c532c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vishruth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ca65830a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Document matrix shape:  (237, 344)\n",
      "No. of words:  344\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['nigga', 'niggas', 'shit', 'fuck', 'fucking',\n",
    "                  'fucked', 'bitch', 'fuckin', 'go', 'got', 'gotta', 'oh', 'get', 'huh', 'yeah' ,'uh', 'man'])\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=0.1)\n",
    "tfidf = vectorizer.fit_transform(data['Lyrics'].values.astype('U'))\n",
    "print(\"Term-Document matrix shape: \", tfidf.A.shape)\n",
    "print(\"No. of words: \", len(vectorizer.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb4b2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba4a9c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic weight for each lyric - matrix shape:  (237, 5)\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=5, init=\"nndsvda\")\n",
    "W = nmf.fit_transform(tfidf)\n",
    "print(\"Topic weight for each lyric - matrix shape: \", W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8daace79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word weight for each topic - matrix:  (5, 344)\n"
     ]
    }
   ],
   "source": [
    "H = nmf.components_\n",
    "print(\"Word weight for each topic - matrix: \", H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "087e8b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "said die one life want high time make inside back baby see two never live come tell take need good\n",
      "Topic 2:\n",
      "like top rock em ya back dot boy rap money jay yo new coast big dawg still pop west let\n",
      "Topic 3:\n",
      "feel like nobody god pussy everything way life stop kill feeling something talkin heart real always damn work em young\n",
      "Topic 4:\n",
      "love people wanna give keep time away real still us black run way need one feeling would night another money\n",
      "Topic 5:\n",
      "know mean day wanna let really kendrick girl new city say told hoes business compton used real bout talk today\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(H):\n",
    "    print(f'Topic {i+1}:')\n",
    "    print(\" \".join(vectorizer.get_feature_names_out()[i] for i in topic.argsort() [:-21:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "200a3698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_labels = ['life and death', 'hip-hop', 'sentiment', 'love', 'himself']\n",
    "topic_values = W\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93b9d88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>life and death</th>\n",
       "      <th>hip-hop</th>\n",
       "      <th>violence</th>\n",
       "      <th>love</th>\n",
       "      <th>himself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.164285</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>0.101668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106258</td>\n",
       "      <td>0.115796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144699</td>\n",
       "      <td>0.062158</td>\n",
       "      <td>0.082499</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>0.070870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027391</td>\n",
       "      <td>0.113370</td>\n",
       "      <td>0.169654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097159</td>\n",
       "      <td>0.094643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>0.109997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.021799</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.052257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.050078</td>\n",
       "      <td>0.219350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.019038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.169224</td>\n",
       "      <td>0.082633</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.037158</td>\n",
       "      <td>0.114585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.138273</td>\n",
       "      <td>0.072361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>0.438867</td>\n",
       "      <td>0.047041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     life and death   hip-hop  violence      love   himself\n",
       "0          0.164285  0.031775  0.005435  0.022480  0.101668\n",
       "1          0.106258  0.115796  0.000000  0.000000  0.031530\n",
       "2          0.144699  0.062158  0.082499  0.043696  0.070870\n",
       "3          0.038647  0.000000  0.027391  0.113370  0.169654\n",
       "4          0.097159  0.094643  0.000000  0.040916  0.109997\n",
       "..              ...       ...       ...       ...       ...\n",
       "232        0.021799  0.045586  0.000000  0.000302  0.052257\n",
       "233        0.050078  0.219350  0.000000  0.013411  0.019038\n",
       "234        0.169224  0.082633  0.002945  0.037158  0.114585\n",
       "235        0.138273  0.072361  0.000000  0.082500  0.000000\n",
       "236        0.008281  0.016087  0.009189  0.438867  0.047041\n",
       "\n",
       "[237 rows x 5 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_data_frame = pd.DataFrame(topic_values, columns = topic_labels)\n",
    "topic_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ad4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c774f8753f60dbf4aa57a14cb39d0d874a7eb06ee0d91865f47ca25147f31953"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
